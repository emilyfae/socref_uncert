---
title             : "Children's social information seeking is sensitive to referential ambiguity"
shorttitle        : "Information seeking reflects uncertainty"
author: 
  - name          : "Emily Hembacher"
    affiliation   : "1"
  - name          : "Benjamin deMayo"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Jane Stanford Way, Stanford, CA, 94305"
    email         : "mcfrank@stanford.edu"
affiliation:
  - id            : "1"
    institution   : "Stanford University"
author_note: |
abstract: |
 We examined children's spontaneous information seeking in response to referential ambiguity. Children ages 2--5 (n=160) identified the referents of familiar and novel labels, and we manipulated ambiguity by changing the number of objects present and their familiarity (Experiments 1 and 2), and the availability of referential gaze (Experiment 2). In both experiments, children looked to the face of the experimenter more often while responding, specifically when the referent was ambiguous. In Experiment 2, 3- to 4-year-olds also demonstrated sensitivity to graded referential evidence. These results suggest that social information seeking is an active learning behavior that could contribute to language acquisition in early childhood.
  
keywords          : "information seeking; active learning; word learning; uncertainty."
wordcount         : "4707"
bibliography      : ["socref.bib"]
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
lang              : "english"
class             : "man"
output            : papaja::apa6_word
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.crop = FALSE, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=FALSE, warning=FALSE, cache=TRUE, message=FALSE, 
                      sanitize = TRUE)
```

```{r, libraries}
# install.packages("devtools")
# devtools::install_github("langcog/langcog")

library(here)
library(papaja)
library(tidyverse)
library(png)
library(ggplot2)
library(xtable)
library(lme4)
library(knitr)
library(markdown)
library(lmerTest)
library(ggthemes)
library(psych)
library(magrittr)
library(langcog)
```


During their first years of life, children gain an understanding of the causal structure of the world, begin to reason about social structures and relationships, and acquire the language spoken around them. How do they learn so much, so quickly? One potential answer comes from the observation that children are not passively absorbing information from the world but instead are constantly exploring, intervening, and asking questions, appearing to be testing out and refining their ideas [@Xu2013;@gopnik2012]. In formal analyses of learning, regimes where learners can select their own datapoints to reduce their uncertainty are referred to as “active learning,” distinguishing them from contexts in which the learner does not have control over the learning input [@Gureckis2012]. Active learning of this type can lead to far more efficient learning from less data [@settles2009] and hence could be a key enabling factor in some of the feats of learning shown by young children.

At least by age three, children show a broad range of potential active learning behaviors, from social referencing to exploration and question-asking  [e.g., @Chouinard2007; @Schulz2007; @Walden1988]. 
They are also increasingly proficient at explicitly identifying gaps in their knowledge and their uncertainty in a wide variety of domains [@Coughlin2014; @Hembacher2014; @Lyons2011; @Rohwer2012]. Indeed, a body of evidence suggests that their behaviors may be motivated by reducing uncertainty [@Ruggeri2017; @Schulz2007; @Vaish2011; @Vredenburgh2015], and that they benefit from the ability to control the timing and content of their learning [@Markant2016]. Thus, at least some of children's exploration is likely to be active learning in the strongest sense. 

Language learning is one of the most impressive accomplishments of children's early years. By their third year, most children know the meanings of hundreds, if not thousands, of words and are combining them to produce utterances that they have never heard before [@fenson1994;@clark2009]. Children's vocabularies grow so rapidly that they must be learning at least a handful of new words each day [@bloom2002]. Much of the research on early word learning has focused on the potential mechanisms by which children could learn so rapidly [e.g., @braginsky2019;@markman1990;@smith2008]. Could active learning be one of these? 

One major challenge of early word learning is referential uncertainty -- the presence of multiple possible referents (objects, in many operationalizations) that could be the target of a particular label [@smith2011]. Both social information and statistical co-occurrence can allow learners to overcome referential uncertainty [e.g., @frank2009;@smith2008]. Social cues like eye-gaze, hand position, and pointing in particular can provide powerful disambiguating information [@frank2013]. Social information is not always present, however, and memory constraints can put limits on co-occurrence learning [@yurovsky2015]. Active learning thus might be one way for learners to reduce referential uncertainty, whether by selecting specific learning examples to be labeled or by asking for clarification of the referent of a label. Indeed, in an artificial language learning experiment with adults, active selection of examples led to substantial gains in learning [@kachergis2013]. 

Children may use active behaviors to reduce referential uncertainty, though less evidence directly licenses this conclusion. One potential example of a mechanism for active information seeking in early word learning comes from research by @walle2014, who reported links between the onset of walking and vocabulary growth [but cf. @moore2019]. A possible mechanism for this developmental connection is that walking children often use their greater ability to carry objects to bring their caregivers objects that interest them. This greater frequency of object offers by walkers leads them in turn to hear more naming [@karasik2014]. Thus, walking children could be learning more words by being better able to (actively) elicit labels for objects of interest. This behavior might not be true active learning, however, since it might not be motivated by specific curiosity about the labels of objects -- as opposed to general desire to share interesting objects -- with the labels being an epiphenomenal accompaniment. 

Object sharing is only one example of a broad class of social behaviors that could provide active learning signals for word learning, however. Another candidate is the search for social signals that disambiguate otherwise ambiguous situations. Imagine a child hears the phrase "where's the spatula" but doesn't know the word "spatula." Will she look to the face of her caregiver, signaling her confusion and seeking clarification? Since disambiguating social signals like eye-gaze are not always present in the field of view of young children [@franchak2011;@franchak2018], the act of social referencing -- looking to an adult for help -- could be a signal of active learning. 

Vaish, Demir and Baldwin [-@Vaish2011] made a first test of this hypothesis, asking whether 12- to 18-month-olds referenced adult gaze when they were uncertain. In that study, children heard an experimenter produce a label for an object in the presence of one or two novel objects. The children looked at the experimenter more often when there were two objects present, suggesting that they were sensitive to some aspect of the uncertainty in the two-object situation. This study supports the idea that even toddlers relatively early on in the language learning process may look for social information in the presence of uncertainty. The present experiments use this paradigm to further explore the extent to which the observed behavior might be a signal of active learning behavior that would be relevant for early word learning. 

To investigate the relationship between referential uncertainty and the search for social information, we conducted two experiments in which we asked children to select the referent of either a known or novel label under different levels of referential uncertainty (with one or two objects present, either familiar, novel, or a combination). We then measured whether they looked to the face of the experimenter (presumably for disambiguating gaze information). To avoid confusion with social referencing in child-caregiver relations [@Walden1988], we call this behavior "social information seeking." Our specific questions were:

1. whether children showed social information seeking selectively in cases of true referential ambiguity (in conditions where there were multiple novel objects); 
2. what the time-course of social information seeking was, relative to a comprehension task; 
3. whether children's social information seeking was sensitive to gradations in uncertainty about reference (operationalized by cases where the referent was unknown but could be inferred from the context); and 
4. whether children's social information seeking was sensitive to the informativeness of the cues provided by their partner. 

Our participants were 2--5 year-old children. Because we wanted to ensure that familiar labels were known to all children in our study, we chose the youngest group in our sample to be older than than the toddlers in @Vaish2011. We also selected a broad age range for our first experiment because we were interested in whether we would observe developmental changes in either the presence or time-course of social information seeking. The range from 2;0 -- 6;0 years spans a developmental period in which children improve substantially in their ability to identify their own ignorance and uncertainty, including in the linguistic domain [@Coughlin2014; @Hembacher2014; @Lyons2011; @Marazita2004; @Rohwer2012]. Thus we hypothesized that we might observe change in this period. (Since we observed limited developmental change in this age range, in Experiment 2 we focused on 3--4 year-olds.)

In sum, our current studies were designed to probe the extent to which children's social information seeking might be reflective of active learning processes relevant to language learning -- that is, a selective search for clarification or guidance in the face of referential uncertainty. 

# Experiment 1

```{r design,  fig.cap= "Study design for Experiments 1 and 2. Children were shown one or two objects, heard a label, and were asked to place the labeled object in a bucket. Referential ambiguity was manipulated through the familiarity of the objects present and through the availability of referential gaze.", fig.width = 6}
img <- png::readPNG(here("writeup/journal/paper/figs/socref_design.png"))
grid::grid.raster(img)
```

In Experiment 1, we examined whether children would seek social information from a speaker more often when the speaker produced a referentially ambiguous label compared to an unambiguous label (question 1 above). In our experiment, children sat across from an experimenter who labeled an object on the table between them. The experimenter then asked the child to place the named object in a bucket. Across trials, there were either one or two objects on the table, which were either familiar or novel to the child. Figure \ref{fig:design} shows the design and condition structure of the experiment. While @Vaish2011 varied the number of objects present in the scene, they did not investigate whether the effect they observed was generally due to the presence of two objects or specific to the ambiguity of the novel label in the presence of two novel objects (in part because the children in their study were so young). If children's social information seeking was selective in this way, we expected children to increase their looking to the experimenter only on trials with two unfamiliar objects, when the object-label mapping was not known and could not be inferred.

We were also interested in the time-course of social information seeking (question 2 above); in particular, whether children's social information seeking was immediately triggered by referential uncertainty or showed some dependency on the child's own action. Because our paradigm was a live interaction between child and experimenter, there was intrinsic variability in timing from to trial. Thus, we were not able to consider absolute time-courses; instead we considered four different phases of each trial based on the notion that children might expect different social information at different stages of the task. Specifically, we predicted that children might expect the speaker's gaze direction to be informative during the labeling itself, as speakers tend to look at objects they refer to [cf. @Vaish2011]. We also predicted that later in the trial, as children reached for an object and placed it in the bucket, they might expect evaluative feedback about their choice (e.g., facial expressions of encouragement or discouragement).

```{r}
load(here("writeup/journal/processed_data/soc_ref_e2.RData"))
plength2 <- psych::describeBy(d$phase_length, d$phase_name)

load(here("writeup/journal/processed_data/soc_ref_e1.RData"))

age_months <- d %>%
  group_by(age_years) %>%
  summarise(mean = mean(age_months))

age_months$age_years <- factor(age_months$age_years,
levels = c(2, 3, 4, 5),
labels = c("two", "three", "four", "five"))

halfs <- d %>%
  mutate(first_half = between(trial, 1, 4)) 

plength1 <- psych::describeBy(d$phase_length, d$phase_name)

phases1 <- data.frame()
phases2 <- data.frame()
phases1 <- bind_rows(phases1, plength1$label, plength1$slide, plength1$planning, plength1$response) %>%
  select(mean, sd) %>%
  mutate(phase = c("label","slide","planning","response"), Experiment = "1")
phases2 <- bind_rows(phases2, plength2$label, plength2$slide, plength2$planning, plength2$response) %>%
  select(mean, sd) %>%
  mutate(phase = c("label","slide","planning","response"), Experiment = "2")

phases <- bind_rows(phases1, phases2) %>%
  select(Experiment, phase, mean, sd)

save(phases, file = here("writeup/journal/processed_data/phases.RData"))
```

## Methods

### Participants

We recruited a planned sample of 80 children ages 2--5 years from the Children's Discovery Museum in San Jose, California^[Planned sample size, exclusion criteria, and analysis plan preregistered at https://osf.io/y7mvt.]. The sample included 20 2-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="two"], 1)` months), 20 3-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="three"], 1)` months), 20 4-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="four"], 1)` months), and 20 5-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="five"], 1)` months). An additional 20 children participated but were removed from analyses because they heard English less than 75% of the time at home (*n* = 10), because they were unable to complete at least half of the trials in the task (*n* = 4), because of parental interference (*n* = 1), or due to experimenter or technical errors (*n* = 5). 

### Stimuli and Design

Children were presented with one or two objects, heard a label, and were asked to put the labeled object in a bucket. Half of the objects were selected to be familiar to children (e.g., a cow) and half were selected to be novel (e.g., an unusual-looking nozzle). The familiar items had names that the majority of children recognize by 24 months [@Frank2016]. There were four possible trial types based on the number and familiarity of the objects present: one familiar object (F), one novel object (N), two familiar objects (FF), and two novel objects (NN). There were three trials of each type, for a total of twelve trials. Trial types were presented sequentially in an order that was counterbalanced across participants. The assignment of individual objects to trial types was counterbalanced. On F and FF trials, the familiar label for the target object was used (e.g., "cow"), and the side of the correct answer was counterbalanced. On N and NN trials, a novel label was used (e.g., "dawnoo").

The critical manipulation was of referential ambiguity; F and FF trials were referentially unambiguous, as children were expected to be certain about the objects and their labels. Similarly, on N trials, children were expected to be certain about the label referent as there was only one option. However, NN trials were referentially ambiguous, as the novel label could apply to either novel object.

Throughout the task, the experimenter never gazed at the object they were labeling or responded to children's verbal or non-verbal bids for help by indicating the correct object. Thus, when two novel objects were present, children were expected to remain uncertain about the referent for the duration of the trial.

### Procedure

Families were recruited from the floor of the museum to join the experimenter in a small research room. Parents were asked to sit quietly to the side. Throughout the study, the child sat at one end of a large circular table, and the experimenter stood at the opposite end. Each trial proceeded as follows: the experimenter placed one or two objects on the left and/or right sides of the table, out of reach of the child so that the child could not interact with the toys during the labeling event. For one-object trials, the location of the object (left or right) alternated between trials. After placing the objects, the experimenter said, “Hey look, there's a (target) here.” The experimenter gazed at the center of the table rather than the object they labeled. The experimenter waited approximately two seconds based on a visual metronome placed within view before saying, “Can you put the (target) in the bucket?” They then pushed the object(s) forward within reach of the child and placed a plastic bucket in the center of the table, also within reach of the child. If the child did not respond within 10 seconds, the experimenter repeated the question. The experimenter provided no accuracy feedback to children throughout the trial. After the child placed an object in the bucket, the experimenter said "okay!" or "thank you!" to maintain a positive interaction without providing information about accuracy. Prior to the twelve experimental trials, there were two training trials: an F trial and an FF trial, to acquaint the child with the procedure. If children chose the wrong object on the FF trial (which happened rarely), they were corrected. A camera placed to the side of the experimenter captured the participant's face, so that looking behavior could be coded from video.

### Coding procedure and analytic plan

```{r}
load(here("writeup/journal/processed_data/soc_ref_e1.RData"))

#how many trials are missing because of child off-task?
missing <- d %>%
  group_by(age_years) %>%
  summarise(excluded = mean(exclude))

missingtwo <- missing$excluded[missing$age_years == 2]
missingthree <- missing$excluded[missing$age_years == 3]
missingfour <- missing$excluded[missing$age_years == 4]
missingfive <- missing$excluded[missing$age_years == 5]
```

Videos were coded using DataVyu software (http://datavyu.org). For each participant, we coded the number of times they referenced the experimenter throughout each trial.^[We did not code looks to the child's parent, although anecdotally these did occasionally occur.] An alternative analytic option would be to simply code whether or not children looked at the experimenter. However, during piloting, we found that most children looked up to the experimenter at least once while they were labeling the object, suggesting that a binary measure of looking would not be meaningful.^[We considered coding absolute looking time to the experimenter, but, given that the experimenter gave no information about their referent, we were uncertain whether longer looking was an adaptive response in this situation. In contrast, more discrete looks to the experimenter could represent "checking in" with the experimenter in the hope that they were now providing relevant information.]

Because we were interested in the precise circumstances in which children feel uncertain enough to reference a speaker, we coded the number of looks that occurred during four distinct phases of the trial: a *label* phase, which began at the utterance of the label and ended when the experimenter began to slide the objects, a *slide* phase, in which the experimenter slid the object(s) into the child's reach, a *planning* phase, which began at the end of the slide and ended when the child touched an object, and a *response* phase, which began when the child touched an object and ended when the child released the object into the bucket. If a look began in one phase but continued into another, we counted it as a look in both phases.

We also noted any trials that should be excluded from analyses due to the child's interference with the timing of the trial (e.g., talking over the experimenter), experimenter error, or outside distractions that interfered with the timing of the trial (e.g., noise from a sibling). These trial-wise exclusion criteria were preregistered. In total, we excluded `r broman::myround(missingtwo*100, 1)`% of trials from 2-year-olds, `r broman::myround(missingthree*100, 1)`% of trials from 3-year-olds, `r broman::myround(missingfour*100, 1)`% of trials from 4-year-olds, and `r broman::myround(missingthree*100, 1)`% of trials from 5-year-olds on this basis. 
A second coder independently scored the number of looks for one third of the trials for each participant to establish reliability. Inter-rater reliability for the number of looks in each phase was high, intraclass correlation *r* = .97, *p* < .001.

Table \ref{tab:phases} displays the average durations of each of the four phases. The *label* and *response* phases are longer on average than the *planning* and *slide* phases. However, note that we are interested in comparing the amount of looking across ambiguity conditions and not across phases directly.

To quantify the effects of the number and familiarity of objects on children's looking, along with any developmental trends, we planned to fit a linear mixed-effects regression. Mixed-effects models account for both fixed and random factors (such as participants and stimuli). Compared with traditional ANOVA approaches, these models provide a more accurate estimate of whether results will generalize beyond the participants and items that were sampled [@Baayen2008]. As recommended by @Barr2013, we begin with a maximal model and trim according to our standard laboratory procedures : `number of looks ~ number of objects * familiarity * phase * age in months + (number of objects * familiarity | subject) + (1 | item)`. Random effects are denoted by parentheses. This model specification was preregistered, as noted above.

## Results

### Accuracy

```{r, echo = FALSE}

#how often did children select two objects or no objects?
ids <- d %>%
 distinct(SID)

trials <- d %>%
 distinct(trial)

n <- length(ids$SID)*length(trials$trial)
n_two <- n/2 #number of two-object trials
n_two_group <- n_two/4 #number of two-object trials per age group

res <- d %>%
  filter(num_objs == 2)%>%
  distinct(SID, trial, response, familiarity, acc, age_years)

#how many kids sometimes picked 2 objects?
two_objs <- res %>%
  filter(response == "LR" | response == "RL")

l1 <- length(unique(two_objs$SID[two_objs$age_years == 2]))
l2 <- length(unique(two_objs$SID[two_objs$age_years == 3]))
l3 <- length(unique(two_objs$SID[two_objs$age_years == 4]))
l4 <- length(unique(two_objs$SID[two_objs$age_years == 5]))

two_kids <- unique(two_objs$SID)

#how often do kids pick 2 objects on 2-object trials?
nc <- length(res$acc[res$response == "NC"])/n_two
b <- length(res$acc[res$response == "B"])/n_two
lr <- length(res$acc[res$response == "LR"])/n_two
rl <- length(res$acc[res$response == "RL"])/n_two
tot <- 100*(lr + rl + b) #percent of trials with two objects placed in bucket

b2 <- length(res$acc[res$response == "B" & res$age_years == 2])/n_two_group
b3 <- length(res$acc[res$response == "B" & res$age_years == 3])/n_two_group
b4 <- length(res$acc[res$response == "B" & res$age_years == 4])/n_two_group
b5 <- length(res$acc[res$response == "B" & res$age_years == 5])/n_two_group

lr2 <- length(res$acc[res$response == "LR" & res$age_years == 2])/n_two_group
lr3 <- length(res$acc[res$response == "LR" & res$age_years == 3])/n_two_group
lr4 <- length(res$acc[res$response == "LR" & res$age_years == 4])/n_two_group
lr5 <- length(res$acc[res$response == "LR" & res$age_years == 5])/n_two_group

rl2 <- length(res$acc[res$response == "RL" & res$age_years == 2])/n_two_group
rl3 <- length(res$acc[res$response == "RL" & res$age_years == 3])/n_two_group
rl4 <- length(res$acc[res$response == "RL" & res$age_years == 4])/n_two_group
rl5 <- length(res$acc[res$response == "RL" & res$age_years == 5])/n_two_group

tot2 <- 100*(lr2 + rl2 + b2) #percent of 2obj trials with two objects placed in bucket
tot3 <- 100*(lr3 + rl3 + b3) #percent of 2obj trials with two objects placed in bucket
tot4 <- 100*(lr4 + rl4 + b4) #percent of 2obj trials with two objects placed in bucket
tot5 <- 100*(lr5 + rl5 + b5) #percent of 2obj trials with two objects placed in bucket

#are trials with 2 objects chosen more likely to be novel?

nov_t <- d %>%
  filter(num_objs == 2) %>%
  distinct(SID, trial, response, familiarity, acc, age_years) %>%
  mutate(both = response == "LR" | response == "RL" | response == "B") %>%
  group_by(SID, age_years, familiarity) %>%
  summarise(both = mean(both))

nov <- d %>%
  filter(num_objs == 2) %>%
  distinct(SID, trial, response, familiarity, acc, age_years) %>%
  mutate(both = response == "LR" | response == "RL" | response == "B") %>%
  group_by(age_years, familiarity) %>%
  summarise(both = mean(both))

t_nov_2 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 2], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 2], paired = TRUE)

t_nov_3 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 3], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 3], paired = TRUE)

t_nov_4 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 4], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 4], paired = TRUE)

t_nov_5 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 5], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 5], paired = TRUE)

#when kids put two objects in bucket, do they put the correct one in first if there is a correct answer?

cor <- d %>%
  filter(num_objs == 2, !is.na(acc), response != "B") %>%
  distinct(SID, trial, response, familiarity, acc, age_years) %>%
  mutate(both = response == "LR" | response == "RL")

acc_sum <- cor %>%
  filter(acc == 1) %>%
  group_by(age_years) %>%
  summarize(both = sum(both))

both_sum <- cor %>%
  group_by(age_years) %>%
  summarize(both = sum(both))
```

```{r}
#Get accuracy for plot
d$acc <- as.numeric(as.character(d$acc))

acctab_e1 <- d %>%
  filter(!is.na(acc),familiarity == "familiar", exclude == 0, num_objs == 2) %>%
  group_by(age_years) %>%
  multi_boot_standard(col = "acc")

acctab_e1$age_years <- as.factor(acctab_e1$age_years)
```  

```{r acce1, fig.cap='Accuracy for FF trials in Experiment 1. Error bars are 95 percent confidence intervals.', fig.width = 4, out.width = "3in"}
ggplot(acctab_e1, aes(age_years, mean)) +
  geom_bar(stat = "identity", position = "dodge") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))  +
  ggthemes::theme_base() + 
  theme(plot.background = element_rect(color = NA)) + 
  labs(x = "Age in Years", y = "Accuracy")
```

```{r phasetable, echo = FALSE, results="asis"}
load(here("writeup/journal/processed_data/phases.RData"))

names(phases) <- c('Experiment','Phase','Mean Duration', 'SD')

print(xtable(phases,
             label = "tab:phases",
             caption = "Phase Durations (in ms)",
             digits = c(0,0,0,0,0)),
      include.rownames = FALSE,
      sanitize.text.function = function(x){x},
      caption.placement = 'bottom',
      table.placement = "b",
      floating = TRUE,
      type = "latex",
      hline.after = c(-1,0, 4,nrow(phases)),
      comment = F)
```

```{r}
load(here("writeup/journal/processed_data/soc_ref_e1.RData"))

#t-test for 2-yo acc
d$acc <- as.numeric(d$acc)

acc_t <- d %>%
  filter(!is.na(acc), exclude == 0) %>%
  group_by(SID, age_years) %>%
  dplyr::summarise(acc = mean(acc))

acctest <- t.test(acc_t$acc[acc_t$age_years == 2], mu = .5)
```

First, to understand whether children were engaged by the task and complying with instructions, 
we examined children's accuracy for those trials in which a correct response was possible (i.e., FF trials). Children sometimes put two items in the bucket (2-year-olds: `r broman::myround(tot2, 1)`% of 2-object trials; 3-year-olds: `r broman::myround(tot3, 1)`%; 4-year-olds: `r broman::myround(tot4, 1)`%; 5-year-olds: `r broman::myround(tot5, 1)`%), despite instructions to choose only one. The first object children put in the bucket was coded as their response. Children in each age group were equally likely to put two objects in the bucket for familiar and unfamiliar trials (2-year-olds: *t*(`r t_nov_2$parameter`) = `r broman::myround(t_nov_2$statistic, 2)`, *p* =`r broman::myround( t_nov_2$p.value, 2)`; 3-year-olds: *t*(`r t_nov_3$parameter`) = `r broman::myround(t_nov_3$statistic, 2)`, *p* =`r broman::myround( t_nov_3$p.value, 2)`; 4-year-olds: *t*(`r t_nov_4$parameter`) = `r broman::myround(t_nov_4$statistic, 2)`, *p* =`r broman::myround(t_nov_4$p.value, 2)`; 5-year-olds: *t*(`r t_nov_5$parameter`) = `r broman::myround(t_nov_5$statistic, 2)`, *p* =`r broman::myround(t_nov_5$p.value, 2)`), suggesting that they put two objects in the bucket because it was a fun activity and difficult to inhibit, and not because they did not know the referent. Among FF trials in which children placed two items in the bucket, they put the correct item in first about half of the time (8/19 trials total for 2-year-olds; 5/6 for 3-year-olds; 0/2 for 4-year-olds; 2/4 for 5-year-olds). 

Children also occasionally declined to choose an item (`r broman::myround(nc*100, 1)`% of trials); these trials are excluded from accuracy analyses. Children's accuracy is displayed in Figure \ref{fig:acce1}. Overall children generally chose the correct item for FF trials, indicating that they understood the task and were motivated to answer correctly. While 3- to 5-year-olds performed close to ceiling (92% - 99%), 2-year-olds were less accurate (76%), but still performed significantly above chance (*t*(19) = `r broman::myround(acctest$statistic, 1)` , *p* < .001).

```{r}
rm(list = ls())
load(here("writeup/journal/processed_data/soc_ref_e1.RData"))
d <- as_tibble(d)
```

```{r}
#get means for plot
msslooks <- filter(d, exclude == 0 | response != "LR" | response != "RL") %>%
  group_by(SID, phase_name, num_objs, familiarity, age_years) %>%
  summarise(num_looks = mean(num_looks))

mslooks <- filter(d, exclude == 0 | response != "LR" | response != "RL") %>%
  group_by(phase_name, familiarity, num_objs, age_years) %>%
  multi_boot_standard(col = "num_looks") 

msslooks_phases <- filter(d, exclude == 0) %>%
  group_by(phase_name) %>%
  summarise(num_looks = mean(num_looks))

msslooks$phase_name <- factor(msslooks$phase_name, levels = c("label","slide", "planning", "response"))
mslooks$phase_name <- factor(mslooks$phase_name, levels = c("label","slide", "planning", "response"))

msslooks$num_objs <- factor(msslooks$num_objs,
levels = c(1,2),
labels = c("One object", "Two objects"))

mslooks$num_objs <- factor(mslooks$num_objs,
levels = c(1,2),
labels = c("One object", "Two objects"))

msslooks$familiarity <- factor(msslooks$familiarity,
levels = c("familiar", "novel"),
labels = c("familiar (F)", "novel (N)"))

mslooks$familiarity <- factor(mslooks$familiarity,
levels = c("familiar", "novel"),
labels = c("familiar (F)", "novel (N)"))

msslooks$age_years <- factor(msslooks$age_years,
levels = c(2, 3, 4, 5),
labels = c("2 years", "3 years", "4 years", "5 years"))

mslooks$age_years <- factor(mslooks$age_years,
levels = c(2, 3, 4, 5),
labels = c("2 years", "3 years", "4 years", "5 years"))
```


```{r resultse1, fig.width=9, fig.height=6, out.width = "6in", fig.cap='Results of Experiment 1. Number of looks to the experimenter based on phase, the number and familiarity of objects present, and age. Age in months was entered as a continuous variable in regression models but is presented here as a categorical variable for visual simplicity. Error bars are 95 percent confidence intervals.'}

ggplot(msslooks, aes(x = phase_name, y = num_looks, 
               col = familiarity, group = familiarity)) + 
  geom_line(data = mslooks, aes(y = mean)) + 
  geom_pointrange(data = mslooks, 
                  aes(y = mean, ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  facet_grid(age_years ~ num_objs) +
  scale_y_continuous(limits = c(0,2), breaks = c(0,1,2)) +
  theme(axis.text.x = element_text(angle = 0, hjust = .5, vjust = .5)) + 
  labs(x = "Phase", y = "Number of Looks") +
  ggthemes::theme_base() + 
  theme(plot.background = element_rect(color = NA)) + 
  ggthemes::scale_color_solarized(name = "Familiarity")
```

```{r include = FALSE}
lmer_data <- d %>%
  filter(!exclude) %>%
  mutate(num_objs = factor(num_objs), 
         familiarity = factor(familiarity), 
         age_c = as.numeric(langcog::scale(age_months, scale = FALSE)),
         phase_name = factor(phase_name),
         soc_ref = social_ref)
```

```{r lmer_e1, results="asis"}
l_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (1  | SID),
           data = filter(lmer_data, phase_name == "label")))

s_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (1  | SID),
           data = filter(lmer_data, phase_name == "slide")))

p_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (1  | SID),
           data = filter(lmer_data, phase_name == "planning")))

r_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (1 | SID),
           data = filter(lmer_data, phase_name == "response")))
```


```{r bayesian, eval=FALSE}
library(brms)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

bmod <- brm(num_looks ~ num_objs * familiarity * age_c + (1 | SID), 
            data = filter(lmer_data, phase_name == "response"), 
            family = poisson())
```


```{r}
#label
e1_l.tab <- as.data.frame(l_lm$coef)

e1_l.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_l.tab$Phase <- c("Label",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_l.tab) <- NULL
e1_l.tab <- e1_l.tab[,c(7,6,1:2,4:5)]
names(e1_l.tab)[4:6] <- c("Std. Error","$t$ value","$p$ value")

#slide
e1_s.tab <- as.data.frame(s_lm$coef)

e1_s.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_s.tab$Phase <- c("Slide",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_s.tab) <- NULL
e1_s.tab <- e1_s.tab[,c(7,6,1:2,4:5)]
names(e1_s.tab)[4:6] <- c("Std. Error","$t$ value","$p$ value")

#planning
e1_p.tab <- as.data.frame(p_lm$coef)

e1_p.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_p.tab$Phase <- c("Planning",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_p.tab) <- NULL
e1_p.tab <- e1_p.tab[,c(7,6,1:2,4:5)]
names(e1_p.tab)[4:6] <- c("Std. Error","$t$ value","$p$ value")

#response
e1_r.tab <- as.data.frame(r_lm$coef)

e1_r.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_r.tab$Phase <- c("Response",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")


rownames(e1_r.tab) <- NULL
e1_r.tab <- e1_r.tab[,c(7,6,1:2,4:5)]
names(e1_r.tab)[4:6] <- c("Std. Error","$t$ value","$p$ value")

e1.tab <- bind_rows(e1_l.tab, e1_s.tab)%>%
  bind_rows(e1_p.tab)%>%
  bind_rows(e1_r.tab)

e1.tab %<>% 
  mutate(
    stars = ifelse(`$p$ value` > .1, "", 
                   ifelse(`$p$ value` < .001, "***",
                          ifelse(`$p$ value` < .01, "**",
                                 ifelse(`$p$ value` < .05, "*",
                                        ifelse(`$p$ value` < .1, ".", "Error"))))),
    
    `$p$ value` = ifelse(`$p$ value` > .1, round(`$p$ value`, 2), 
                         ifelse(`$p$ value` < .001, "$<$ .001",
                                ifelse(`$p$ value` < .01, round(`$p$ value`, 2),
                                       ifelse(`$p$ value` < .05, round(`$p$ value`, 2),
                                              ifelse(`$p$ value` < .1, round(`$p$ value`, 2), 
                                                     "Error")))))
  )

names(e1.tab)[7] <- c("")

save(e1.tab, file = here("writeup/journal/processed_data/e1tab.RData"))
```

```{r echo = FALSE}
#histogram for number of looks by phase. 
load(here("writeup/journal/processed_data/soc_ref_e1.RData"))

hist_e1 <- d %>%
   select(phase_name, num_looks) %>%
  mutate(Experiment = "Experiment 1")

load(here("writeup/journal/processed_data/soc_ref_e2.RData"))

hist_e2 <- d %>%
   select(phase_name, num_looks) %>%
  mutate(Experiment = "Experiment 2")

hist <- hist_e1 %>%
  bind_rows(hist_e2)

hist$phase_name <- factor(hist$phase_name,
levels = c("label", "slide", "planning", "response"),
labels = c("Label", "Slide", "Planning", "Response"))
```

```{r hist, fig.width=8, out.width = "6in", fig.cap='Histograms of the total number of looks to the speaker in each phase of each experiment, irrespective of condition.'}
ggplot(hist, aes(num_looks, fill = num_looks)) +
  geom_histogram(stat = "count") +
  facet_grid(Experiment~phase_name) +
  ggthemes::theme_base() + 
  theme(plot.background = element_rect(color = NA)) + 
  labs(x = "Number of looks", y = "Trial count") +
  ggthemes::scale_fill_solarized(name = "Trial type")
```

### Social information seeking and referential ambiguity

We next examined children's looking behavior for each trial type across the four phases of the trial (Figure \ref{fig:resultse1}). The distribution of number of looks are presented in figure \ref{fig:resultse1}. Note that the most common response is to reference the speaker at least once during the *label* phase, but to not reference the speaker at all during the other phases. 

To test our prediction that referential ambiguity (i.e., having two novel objects) would produce more looking, we fit mixed-effects linear regression models separately for each phase with the following structure: `number of looks ~ number of objects * familiarity * age in months + (number of objects + familiarity | subject)`. Our initial planned analysis, a single model with phase as a factor, did not converge, and the model was subsequently trimmed according to our standard laboratory analytic procedures. Our final models included a random intercept by subject. 

We did not find any main or interaction effects of number of objects, familiarity, or age on number of looks during the *label* phase (Table 2). We also did not observe any significant effects in the *slide* phase. However, we found an interaction effect of number of objects and familiarity during the *planning* ($\beta$ = `r broman::myround(p_lm$coefficients[5], 2)`, *p* < .001) and *response* phases ($\beta$ = `r broman::myround(r_lm$coefficients[5], 2)`, *p* < .001), such that NN trials were associated with more looks. Age did not interact with number of objects or familiarity. 

### Trial-ordering effects

```{r}
lmer_data$trial_c <- as.numeric(langcog::scale(lmer_data$trial, scale = FALSE))
r_lm_order <- summary(lmer(num_looks ~ num_objs * familiarity * age_c * trial_c +
             (1 | SID),
           data = filter(lmer_data, phase_name == "response")))
```


One possible issue in our experimental paradigm was that -- although we were interested in social information seeking -- our setup actually discouraged this behavior. In order to avoid order confounds, the experimenter's gaze was intentionally uninformative as to their intention. This uninformative response may have led children to seek social information less over the course of the experiment. To investigate this hypothesis, we fit an exploratory model to data from the response phase that included both a main effect of trial number and interactions of trial number with age, familiarity, and number of objects. This model had a very comparable interaction of number of objects and familiarity to the model without trial number ($\beta$ = `r broman::myround(r_lm_order$coefficients[6], 2)`, *p* < .001). Unexpectedly, it also showed a small but reliable positive interaction of trial with age ($\beta$ = `r broman::myround(r_lm_order$coefficients[11], 3)`, *p* = `r broman::myround(r_lm_order$coefficients[11,5], 3)`) and a small negative interaction with novelty and age ($\beta$ = `r broman::myround(r_lm_order$coefficients[15], 3)`, *p* = `r broman::myround(r_lm_order$coefficients[15,5], 3)`). Thus, overall, older children may have been looking more as the experiment progressed and less specifically at novel objects. Importantly, there was no reliable main effect of trial number ($\beta$ = `r broman::myround(r_lm_order$coefficients[5], 2)`, *p* < `r broman::myround(r_lm_order$coefficients[5,5], 3)`). 


## Discussion

In summary, children looked to the speaker more often when planning and executing a response under uncertainty. This result suggests that children were aware that they did not have sufficient knowledge to identify the referent and act on it and referenced the speaker to resolve this uncertainty. Surprisingly, we did not observe an effect of age, suggesting that by age 2 children are already selective in their information seeking to resolve referential ambiguity.

Notably, and in contrast to Vaish et al., we did not find the expected effect of referential ambiguity in the *label* phase. Thus, mere novelty or the presence of multiple objects was not enough to increase children's looking when the experimenter was producing the label. Since individuals tend to look at someone who is speaking, children may have looked at the experimenter at least once regardless of referential ambiguity, minimizing possible condition differences. It is also possible that children failed to predict that they would need more information until later in the trial, when they were actually faced with making a decision. A third possibility is that this finding is an artifact of our design, in which the speaker gazed at the center of the table rather than the referent of the label. Children may have realized that the speaker's gaze direction during labeling was not informative. 

Relatedly, one general concern about our paradigm is that children may have found it strange to interact with a speaker who did not gaze at the object they were labeling. Although we did not find trial-order effects supporting this idea, this oddity effect might still have been present from the beginning of the experiment onward. Experiment 2 tests these possibilities and further examines whether children's information seeking is sensitive to graded uncertainty.

# Experiment 2

Experiment 2 was designed to achieve several goals. We aimed to replicate the finding from Experiment 1 that children reference a social partner on the basis of referential ambiguity while executing a decision. 

We also aimed to test whether children's information seeking is graded with respect to graded evidence about a label's referent (question 3, as posed in the Introduction). Evidence for graded information seeking would suggest that this behavior might be a valuable active learning behavior, as it would be responsive to the learner's level of uncertainty (rather than, for example, only being cued by complete ignorance -- as in our NN condition). To this end, in Experiment 2, we added trials with 1 novel and 1 familiar object (FN) and a novel label. This condition contains evidence about reference since the familiar item can be excluded [@Markman1988], but may not be as conclusive as trials with a familiar target. Thus, we predicted that, in the aggregate, children would show the most looking to the speaker in the NN condition, the least in the FF condition, and an intermediate amount in the FN condition. This ordering of conditions would provide evidence for gradedness in the aggregate representation of referential uncertainty.

Further, we aimed to test whether the social information seeking behavior we measured in Experiment 1 was sensitive to the informativeness of the speaker (question 4). To accomplish this, we manipulated between participants whether or not the speaker gazed at the objects they referred to, and thus, whether or not their gaze was an informative cue to reference. We predicted that having access to referential gaze as an informative cue would make children less likely to reference the speaker during their decision, but perhaps more likely to reference the speaker during labeling. Critically, this manipulation also allowed us to test whether Experiment 1 was compromised by the uninformativeness of the experimenter. 

We made several other minor design modifications based on the results of Experiment 1. Since we did not observe any difference between F and N trials in Experiment 1, we eliminated single-object trials. As we did not observe major developmental differences in Experiment 1, we restricted the sample to 3- and 4-year-olds. Three- and 4-year-olds were chosen because we planned to include age in months as a continuous variable in our regression models, and contiguous age groups are thus preferable. Furthermore, 2-year-olds seemed to have more difficulty completing the task in Experiment 1, as evidenced by their lower accuracy rate and higher rate of placing two objects in the bucket.

## Methods

```{r}
rm(list = ls())
load(here("writeup/journal/processed_data/soc_ref_e2.RData"))
```

```{r}
#how many statements of uncertainty and questions?
utterances <- d %>%
  group_by(trial_type) %>%
  summarise(sou = mean(num_sou), ques = mean(num_ques))

missing <- d %>%
  group_by(age_years) %>%
  summarise(excluded = mean(exclude))

missingthree <- missing$excluded[missing$age_years == 3]
missingfour <- missing$excluded[missing$age_years == 4]

age_months <- d %>%
  group_by(age_years) %>%
  multi_boot_standard(col = "age_months")

age_months$age_years <- factor(age_months$age_years,
levels = c(3, 4),
labels = c("three", "four"))
```

### Participants

We recruited a planned sample of 80 children ages 3--4 years from the Children's Discovery Museum in San Jose, California^[Planned sample size, exclusion criteria, and analysis plan (including model specification) preregistered at https://osf.io/y7mvt/.]. The sample included 40 3-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="three"], 1)` months) and 40 4-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="four"], 1)` months). An additional 20 children participated but were removed from analyses because they heard English less than 75% of the time at home (*n* = 9), because they were unable to complete at least half of the trials in the task (*n* = 7), or due to experimenter or technical errors (*n* = 4).

### Stimuli and Design

The stimuli and design were similar to Experiment 1 but included three trial types: FF, NN, and FN. There were four of each trial type, totaling twelve trials. In addition, we manipulated the experimenter's gaze behavior between participants. For half of the participants, the experimenter gazed at the center of the table while labeling objects (uninformative gaze); for the remaining half, they gazed directly at the particular object they were labeling (informative gaze).

### Procedure

The experimental and coding procedures were identical to Experiment 1, except that there were three practice trials (two FF trials and one NN trial). We chose this approach so that children could experience both familiar and novel stimuli during practice but would not be discouraged by an overly difficult practice session. As in Experiment 1, children were corrected if they chose the wrong object on FF trials but not NN trials. 

We again noted trials that should be excluded based on the same criteria as in Experiment 1. We excluded `r broman::myround(missingthree*100, 1)`% of trials from 3-year-olds and no trials from 4-year-olds. Inter-rater reliability for the number of looks in each phase was again high, intraclass correlation *r* = .97, *p* < .001. 
The mean durations of the phases for Experiment 2 are presented in Table 1. They varied in length according to the same pattern as in Experiment 1. 

## Results and Discussion

### Accuracy

```{r}
d$acc <- as.numeric(as.character(d$acc))

acc_mss_e2 <- d %>%
  filter(!is.na(acc), exclude == 0) %>%
  group_by(trial_type, Gaze, age_years) %>%
  multi_boot_standard(col = "acc")

acc_mss_e2$Gaze <- factor(acc_mss_e2$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Gaze", "No gaze"))

acc_mss_e2$trial_type <- factor(acc_mss_e2$trial_type,
levels = c("familiar","mutual", "novel"),
labels = c("FF", "FN", "NN"))

acc_mss_e2$age_years <- as.factor(acc_mss_e2$age_years)
```

```{r acce2, fig.env='figure*',fig.width=7, fig.height=3, out.width="5in", fig.cap='Accuracy for trials with a correct answer available (FF and FN, and all gaze trials) in Experiment 2. Error bars are 95 percent confidence intervals.'}
ggplot(acc_mss_e2, aes(age_years, mean, fill = trial_type)) +
  geom_bar(stat = "identity", position = "dodge") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9)) + 
  facet_wrap(~ Gaze)  +
  ggthemes::theme_base() + 
  theme(plot.background = element_rect(color = NA)) + 
  labs(x = "Age in Years", y = "Accuracy") +
  ggthemes::scale_fill_solarized(name = "Trial type")
```

```{r echo = FALSE}
#how often did children select two objects or no objects?
ids <- d %>%
 distinct(SID)

trials <- d %>%
 distinct(trial)

n <- length(ids$SID)*length(trials$trial)
n_two <- n #number of two-object trials
n_two_group <- n_two/2 #number of two-object trials per age group

res <- d %>%
  distinct(SID, trial, response, trial_type, acc, age_years)

#how often do kids pick 2 objects on 2-object trials?
nc <- length(res$acc[res$response == "NC"])/n_two
b <- length(res$acc[res$response == "B"])/n_two
lr <- length(res$acc[res$response == "LR"])/n_two
rl <- length(res$acc[res$response == "RL"])/n_two
tot <- 100*(lr + rl + b) #percent of trials with two objects placed in bucket

b3 <- length(res$acc[res$response == "B" & res$age_years == 3])/n_two_group
b4 <- length(res$acc[res$response == "B" & res$age_years == 4])/n_two_group

lr3 <- length(res$acc[res$response == "LR" & res$age_years == 3])/n_two_group
lr4 <- length(res$acc[res$response == "LR" & res$age_years == 4])/n_two_group

rl3 <- length(res$acc[res$response == "RL" & res$age_years == 3])/n_two_group
rl4 <- length(res$acc[res$response == "RL" & res$age_years == 4])/n_two_group

tot3 <- 100*(lr3 + rl3 + b3) #percent of 2obj trials with two objects placed in bucket
tot4 <- 100*(lr4 + rl4 + b4) #percent of 2obj trials with two objects placed in bucket

#are trials with 2 objects chosen more likely to be novel?

nov_t <- d %>%
  distinct(SID, trial, response, trial_type, acc, age_years, Gaze) %>%
  mutate(both = response == "LR" | response == "RL" | response == "B",
         unambiguous = trial_type == "mutual" | trial_type == "familiar" | Gaze == "gaze") %>%
  group_by(SID, age_years, trial_type) %>%
  summarise(both = mean(both))

nov <- d %>%
  distinct(SID, trial, response, trial_type, acc, age_years, Gaze) %>%
  mutate(both = response == "LR" | response == "RL" | response == "B",
         unambiguous = trial_type == "mutual" | trial_type == "familiar" | Gaze == "gaze") %>%
  group_by(age_years, unambiguous) %>%
  summarise(both = mean(both))

#not enough observations for t-test

#when kids put two objects in bucket, do they put the correct one in first if there is a correct answer?

cor <- d %>%
  filter(!is.na(acc), response != "B") %>%
  distinct(SID, trial, response, trial_type, acc, age_years) %>%
  mutate(both = response == "LR" | response == "RL")

cor$acc <- as.numeric(cor$acc)

acc_sum <- cor %>%
  filter(acc == 1) %>%
  group_by(age_years) %>%
  summarize(both = sum(both))

both_sum <- cor %>%
  group_by(age_years) %>%
  summarize(both = sum(both))
```

```{r}
lmer_data <- d %>%
  filter(!exclude) %>%
  mutate(trial_type = factor(trial_type), 
         age_c = as.numeric(langcog::scale(age_months, scale = FALSE)),
         phase_name = factor(phase_name), 
         gaze = factor(Gaze),
         acc = factor(acc),
         soc_ref = social_ref)
```

```{r}
lmer_data$trial_type <- relevel(lmer_data$trial_type, ref = "familiar")
lmer_data$gaze <- relevel(lmer_data$gaze, ref = "no_gaze")

acc_mod <- summary(glmer(acc ~ trial_type * gaze + age_c  +
                           (1| SID), 
                         data = lmer_data,
                       family = "binomial"))
```

We again begin by analyzing children's task accuracy for trials with a correct answer possible (i.e., FF, FN, and all trials with gaze), which we calculated using the same criteria as in Experiment 1 (Figure \ref{fig:acce2}). Children sometimes put two items in the bucket, although they did so less frequently than in Experiment 1, perhaps because there were two objects available on every trial and it was thus less of a novelty (3-year-olds: `r broman::myround(tot3, 1)`% of trials; 4-year-olds: `r broman::myround(tot4, 1)`%). As in Experiment 1, the first item they placed in the bucket was coded as their response. 

To quantify the effects of familiarity, gaze, and age on accuracy, we fit the following mixed-effects logistic regression model: `correct ~ trial type * gaze + age in months + (1| subject)`. Age did not significantly predict accuracy ($\beta$ = `r broman::myround(acc_mod$coefficients[5], 2)`, *p* = .12). Accuracy was significantly lower for NN ($\beta$ = `r broman::myround(acc_mod$coefficients[2], 2)`, *p* < .001) and FN trials ($\beta$ = `r broman::myround(acc_mod$coefficients[3], 2)`, *p* < .001) compared to FF trials, and trial type interacted with gaze condition such that accuracy was significantly higher in the gaze condition for NN ($\beta$ = `r broman::myround(acc_mod$coefficients[6], 2)`, *p* < .001) and FN trials ($\beta$ = `r broman::myround(acc_mod$coefficients[7], 2)`, *p* < .001). This last result is a useful check of our gaze manipulation; it suggests that children effectively made use of the social information that was present in the gaze condition. 

### Information seeking and referential ambiguity

```{r}
lmer_data$trial_type <- relevel(lmer_data$trial_type, ref = "mutual")

lm_l <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "label")))

lm_s <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "slide")))

lm_p <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "planning")))

lm_r <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "response")))
```

Experiment 2 was designed to test whether different amounts of referential evidence elicit differential amounts of social information seeking. If so, this would suggest that young children are sensitive to graded evidence for a hypothesis (e.g., that a certain object is the "blicket"). The amount of referential evidence was manipulated through the familiarity of objects presented (NN vs FN vs FF trials) and whether or not gaze was informative (gaze vs. no gaze). If children are sensitive to graded evidence, we might expect a pattern of looking that conforms to the ordering NN > FN > FF and no gaze > gaze, with the possibility of an interaction between gaze condition and familiarity.

Children's patterns of looking based on familiarity and gaze condition are presented in \ref{fig:resultse2}. To quantify the main and interactive effects of familiarity, gaze condition, and age on children's looking, we fit separate mixed-effects linear regression models for each phase (*label*, *slide*, *planning*, *response*) with the following structure: `number of looks ~ familiarity * age in months * gaze + (1 | subject)`.

We found no effect of familiarity, gaze condition, or age on looking in the *label* phase (Table 3). In the *slide* phase both FF ($\beta$ = `r broman::myround(lm_s$coefficients[2], 2)`, *p* < .01) and NN trials ($\beta$ = `r broman::myround(lm_s$coefficients[3], 2)`, *p* = .047) elicited more looking compared to FN trials, and there were no effects of or interactions with gaze condition or age. The directionality of the FF finding especially was unpredicted, and we interpret it with caution due to both the mismatch between this result and the results in the subsequent phases and the very low overall levels of looking in this phase. 

In the *planning* phase, we found that FF trials were associated with less looking than FN trials ($\beta$ = `r broman::myround(lm_p$coefficients[2], 2)`, *p* = .045) and NN trials were associated with more looking compared to FN trials ($\beta$ = `r broman::myround(lm_p$coefficients[3], 2)`, *p* < .01), and there were no effects of or interactions with gaze condition or age. 

Similar to the *planning* phase, in the *response* phase, FF trials elicited less looking ($\beta$ = `r broman::myround(lm_r$coefficients[2], 2)`, *p* < .001) and NN trials elicited more looking ($\beta$ = `r broman::myround(lm_r$coefficients[3], 2)`, *p* = .02) compared to FN trials. In addition, the gaze condition was associated with less looking compared to the no-gaze condition ($\beta$ = `r broman::myround(lm_r$coefficients[5], 2)`, *p* = .03), and gaze interacted with familiarity such that FF trials in the gaze condition were associated with more looking than FF trials in the no-gaze condition ($\beta$ = `r broman::myround(lm_r$coefficients[8], 2)`, *p* < .01). There were no significant main effects or interactions of age. 

In summary, in the *planning*, and *response* phases, children showed the pattern of responding with respect to graded evidence that we predicted. They looked at the experimenter the most for NN trials, the least for FF trials, and an intermediate amount for FN trials. This finding suggests that the likelihood of children seeking disambiguating information is tuned to the amount of referential evidence they receive. Further supporting this idea, children looked more at the experimenter when she did not gaze at the object she was referring to during labeling, suggesting that children attended to this evidence and it contributed to their certainty in their response. Additionally, familiarity interacted with gaze condition, but not in the predicted direction. Instead, FF trials with referential gaze elicited more looking than FF trials without referential gaze. 

Finally, similar to Experiment 1, we did not observe selective looking during the *label* phase, even among children in the gaze condition. This result rules out the possibility that children were less selective during labeling during Experiment 1 because they learned that the experimenter's gaze direction was not informative (confirming our exploratory trial order analysis). Instead, young children may attend to someone who is speaking regardless of the need for disambiguation.

```{r eval=FALSE}
lmer_data$trial_c <- as.numeric(langcog::scale(lmer_data$trial, scale = FALSE))
lm_r_order <- summary(lmer(num_looks ~ trial_type *  age_c * gaze * trial_c  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "response")))
```


```{r}
#get means for plot
msslooks <- filter(d, exclude == 0) %>%
  group_by(SID, phase_name, trial_type, Gaze, age_years) %>%
  summarise(num_looks = mean(num_looks))

mslooks <- filter(d, exclude == 0) %>%
  group_by(phase_name, trial_type, Gaze, age_years) %>%
  multi_boot_standard(col = "num_looks") 

msslooks$phase_name <- factor(msslooks$phase_name, levels = c("label","slide", "planning", "response"))
mslooks$phase_name <- factor(mslooks$phase_name, levels = c("label","slide", "planning", "response"))

msslooks$trial_type <- factor(msslooks$trial_type, labels = c("FF","FN", "NN"))
mslooks$trial_type <- factor(mslooks$trial_type, labels = c("FF","FN", "NN"))

msslooks$Gaze <- factor(msslooks$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Referential gaze", "No referential gaze"))

mslooks$Gaze <- factor(mslooks$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Referential gaze", "No referential gaze"))

msslooks$age_years <- factor(msslooks$age_years,
levels = c(3, 4),
labels = c("3 years", "4 years"))

mslooks$age_years <- factor(mslooks$age_years,
levels = c(3, 4),
labels = c("3 years", "4 years"))

msslooks <- msslooks %>%
  mutate(familiarity = trial_type)

mslooks <- mslooks %>%
  mutate(familiarity = trial_type)
```

```{r resultse2, fig.width=9, fig.height=5, out.width="6in", fig.cap='Results of Experiment 2. Number of looks to the experimenter based on phase, trial type, gaze condition, and age. Age in months was entered as a continuous variable in regression models but is presented here as a categorical variable for visual simplicity. Error bars are 95 percent confidence intervals.'}

ggplot(msslooks, aes(x = phase_name, y = num_looks, 
               col = familiarity, group = familiarity)) + 
  geom_line(data = mslooks, aes(y = mean)) + 
  geom_pointrange(data = mslooks, 
                  aes(y = mean, ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  facet_grid(age_years ~ Gaze) + 
  scale_y_continuous(limits = c(0,2), breaks = c(0,1,2)) +
  theme(axis.text.x = element_text(angle = 0, hjust = .5, vjust = .5)) + 
  labs(x = "Phase", y = "Number of Looks")  +
  ggthemes::theme_base()  +
  theme(plot.background = element_rect(color = NA)) + 
  ggthemes::scale_color_solarized(name = "Familiarity")
```

# General Discussion


<!-- 1. whether children showed social information seeking selectively in cases of true referential ambiguity (in conditions where there were multiple novel objects);  -->
<!-- 2. what the time-course of social information seeking was, relative to a comprehension task;  -->
<!-- 3. whether children's social information seeking was sensitive to gradations in uncertainty about reference (operationalized by cases where the referent was unknown but could be inferred from the context); and  -->
<!-- 4. whether children's social information seeking was sensitive to the informativeness of the cues provided by their partner.  -->

An increasing body of evidence suggests that children's exploratory and social behaviors are "active learning" behaviors -- that they are motivated by resolving uncertainty. Active learning could thus be an important component of how we explain young children's impressive learning abilities. In the experiments reported here, we explored whether children showed active learning behaviors that might be relevant for language learning. Specifically, we investigated whether social information seeking -- looking to the face of an experimenter for potential gaze information -- was related to uncertainty about the referent of the experimenter's request. Our data strongly supported this hypothesis: the level of referential uncertainty in the trial was associated with children's information seeking [broadly replicating the findings of @Vaish2011]. This general finding allows us to return to the questions about the nature of social information seeking posed in the Introduction.

We found that social information seeking was selective (question 1). Across both experiments, children looked to the experimenter more in the NN condition, when there were two objects with unknown names, than in any other condition. Further, this selectivity appeared to be graded (question 3). In the case of FN trials in Experiment 2, children could solve the problem of reference by excluding the familiar item [@Markman1988; @Merriman1989], and indeed, they chose the correct object most of the time in these trials. If children had simply monitored the presence or absence of some cue to interpret meaning, they would have consistently responded to FN trials with certainty. Instead -- at least in their aggregate performance -- they sought information in a graded fashion, looking at the experimenter less than for NN trials but more than for FF trials. They also exhibited less looking on these trials when referential gaze was present than when it was not. 
<!-- Intriguingly, children appear to remain uncertain when their only cue to reference is the adult's gaze during labeling — there was no difference between NN trials with and without gaze. This finding suggests that referential gaze may be a weaker cue compared to ruling out a familiar object. -->

With respect to the observed time-course of selective information seeking (question 2), we found evidence for this behavior when children were planning and executing their decision. We speculate that children referenced the speaker during the decision process because they expected evaluative feedback about their demonstrated choice, either implicitly through the adult's facial expressions, or through an explicit response. This idea is consistent with other recent findings that preschoolers and toddlers seek help selectively when a problem is difficult or they are less skilled [@Goupil2016; @Vredenburgh2015]. On the other hand, we found no evidence for selective information seeking while the speaker was producing the label. One possibility is that young children do not recognize the need for disambiguating information until they need to make a decision [@Markman1977]. Another possibility is that children spontaneously look at a speaker regardless of ambiguity, and additional looking was not necessary. This latter possibility seems more credible, given that children typically looked at the speaker at least once during labeling. Notably, @Vaish2011 observed selective referencing during labeling among infants. Since infants in that study were holding one of the objects during labeling, perhaps referencing the speaker would have required them to disengage from that object, leading to a higher threshold for referencing the speaker. 

Finally, with respect to the sensitivity of information seeking to speaker informativeness (question 4), we observed mixed findings. In Experiment 1, the experimenter was never informative with their gaze, and yet we did not observe consistent decreases in looking over the course of the experiment; children continued to look to the experimenter even though they never got any useful feedback. On the other hand, in Experiment 2, when we explicitly manipulated the presence of a gaze cue, we did see some effect. First, children did use the gaze cue to identify the correct referent in ambiguous situations. Second, we observed less social information seeking in the partially-ambiguous FN condition when there was also referential gaze information, suggesting that children were combining information across the two cues. Pooling these observations, we speculate that children were motivated enough to look for feedback in the ambiguous situations that they were not immediately dissuaded by the lack of information from the speaker; but when gaze information was obviously present, they did not seek further confirmation.

Contrary to our expectations, we did not observe developmental differences in children's information seeking. We sampled a broad age range (2;0 to 6;0 years) due to previous evidence for improvements in meta-cognitive performance during the preschool years [e.g., @Hembacher2014; @Marazita2004; @Rohwer2012]. However, we found that 2-year-olds were equally likely to be selective in their information seeking compared to 5-year-olds. There are several possible explanations for this finding. It could be that children's monitoring of referential ambiguity and ability to selectively seek out disambiguating evidence are both firmly in place by age 2, and do not develop in the following years. Indeed, there is evidence from Vaish et al. that infants ages 13 and 18 months selectively reference a speaker's gaze direction when her referent is ambiguous, suggesting that sensitivity to lexical uncertainty develops early. Typically-developing children acquire a substantial vocabulary by age 2 [@Goldfield1990], so if lexical uncertainty monitoring is important for language acquisition, it may not be surprising that 2-year-olds demonstrate this ability. One other possible explanation, however, is that we did not see developmental change in this ability because further development happens even beyond the ages we tested -- indeed, supporting this idea, @legare2013 found changes in active question-asking such that 6-year-olds showed a different pattern than 4- and 5-year-olds. 



<!-- These physical and cognitive developmental trajectories may proceed in parallel to metacognitive advancements that allow children to more acutely identify gaps in knowledge that they can then seek to fill. -->

<!-- Another possibility is that children's awareness of uncertainty (in the linguistic domain and beyond) becomes more concrete throughout early childhood, but that information-seeking is a particularly sensitive measure of early uncertainty monitoring compared to explicit report (see Kloo et al. for a similar argument). This possibility would help to explain the difference between the results we observed in the current study, and those of Marazita and Merriman, who found that the majority of 2.5-year-olds failed to explicitly report on their metalinguistic ignorance. Developmental differences in information-seeking during early childhood could be minimal because they do not rely as strongly on later-developing metacognitive processes and verbal ability. -->

<!-- These findings are important given that the ability to monitor the likelihood of accuracy based on graded evidence is assumed important for decision-making and behavioral regulation across development [@Krebs2010; @Yeung2012]. Being able to monitor graded epistemic uncertainty allows individuals to gate out information that does not meet a criterion level of certainty based on individual goals or task demands [@Koriat1996]. The current findings are consistent with the possibility that preschoolers engage in this type of reasoning, given that their uncertainty tracked quantitatively with the amount of evidence available. -->

The primary contribution of our work here is that our findings provide evidence for selective social information seeking as a route for children to resolve referential ambiguity. This behavior could enable faster word learning, especially in cases where children are actively producing behavioral responses on which they would like feedback (since this was the place where we observed the most selective information seeking). Thus, this research makes explicit the potential contribution of active learning behaviors to early word learning. 

More generally, the behavior we examined here -- gaze to an interlocutor's face -- likely relates to a spectrum of active learning behaviors beginning in infancy, all of which could potentially accelerate vocabulary learning relative to passive observation. First, infants direct their attention to salient aspects of the environment that are most likely to yield information, especially from social sources, including faces and hands [@Farroni2002; @Frank2014]. As infants learn to locomote, first by crawling and then by walking, they are able to use this set of behaviors to access to a broader set of information sources [@Kretch2013]. Then, as children learn to speak and to manipulate objects in the environment, they have more opportunity still to seek out information to disambiguate areas of uncertainty, for example by making bids to talk about objects, asking verbal questions, or searching for feedback (as in our study).  

Our study has a number of limitations that suggest directions for future work. First, although we assume that children hoped to glean disambiguating information from the adult experimenter when they visually referenced her, we do not know what type of evidence they expected to receive (e.g., direct help, informative gaze, or an affective response). This is especially relevant as children of different ages, despite showing the same patterns of looking, might have had distinct expectations about the type of information or help they would receive. Second, in Experiment 1, children sometimes ignored the instruction to place only one item in the bucket, particularly 2-year-olds. Although we speculate that younger children showed this behavior because they found it entertaining to place both objects in the bucket, this behavior could also reflect a different understanding or approach to the task compared to older children. Future research should attempt to measure information-seeking behavior in a range of tasks that equate for difficulty across ages. Third, although we were interested in referential uncertainty generally, we instantiated this construct with a specific manipulation using novel words; other cases of referential uncertainty may elicit other behaviors. 

Finally, as with other research on convenience populations, the generality of the responses we observed is unknown. Our research was conducted with a local museum population in the United States. Our work with this population suggests that children at our specific museum largely come from highly-educated families, despite some diversity in terms of race and ethnicity. Children growing up in such families would be most likely to have a high expectation that the adults in their lives would be responsive to their requests for information. Thus, it is a question for future work the degree that the information-seeking responses we observed are general across different populations of children. 

<!-- Overall, these results provide further evidence that preschool-aged children monitor graded uncertainty in their mental representations generally, and in referential ambiguity specifically. Furthermore, they act on that uncertainty through spontaneous information-seeking. These behaviors may in part underlie the rapid acquisition of language during early childhood. -->

# Acknowledgements

We thank Veronica Cristiano for assisting with data collection. EH was supported by a generous gift from Kinedu SAPI de CV. 

# References 

```{r}

```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


